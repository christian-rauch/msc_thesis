\begin{abstract}

Humanoid manipulator with several degree of freedom are versatile applicable to a variety of tasks by using man-made tools as opposed to task-specific manipulators. This comes with the cost of more complex control over the state of this manipulator and the tool.

This work addresses the problem of articulated manipulator and object tracking using visual feedback from the robot's own perception system. Current research has addressed different aspects of the problem like pose estimation of independent rigid parts, but only a few publications have addressed the specific case of manipulator and object tracking in the case where the state of the manipulator in respect to the observation frame is known.

The main contribution of this work is the investigation of the combined usage of visual perception and prior information from the reported manipulator state for a gradient based optimization approach.
This is motivated by the fact that gradient based approaches by design face the issue of local minimums in the objective function.

The evaluation of the gradient based approach using visual perception only, and using additional prior information, will on one side demonstrate the adverse effect of local minima for a manipulation task, and on the other side will show the benefits of exploiting prior information in the very same setting.
In this context, the work also addresses the issue of joint position encoder calibration as these values are the foundation of the exploited prior information.


\end{abstract}