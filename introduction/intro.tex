\chapter{Introduction}

\section{Motivation}

Amongst all robot types, humanoid robots are one of the most versatile robots when it comes to acting in a world with man-made structures and tools. As such, they are a huge area of research involving multiple disciplines. Of special research interest is humanoid manipulation using hands that resemble human hands. Manipulators with several degree of freedom enables robots to reuse man-made tools to solve different kind of problems as opposed to be restricted to task-specific manipulators. Some of the tasks defined for the DARPA robotics challenge \cite{DRC2013} intended to advance robotic manipulation into this direction by setting a robot in a rescue scenario that involves the interaction with door handles (Door task), turning valves (Valve task), connecting a hose to a wye (Hose task) and using a drill to cut a hole in a wall (Wall task). Since the DRC rules stated that the robot needed to carry all of its manipulators during each trial, teams were force to use versatile manipulators.

The advantage of having such a generic manipulator comes with the costs of more complex control. Humanoid manipulation does not involve only the grasping of a tool but also the continuous control of this tool for the duration of the task. Since grasped tools are only indirectly connected to the robot's kinematic chain, additional perceptual information is needed to estimate and track the actual state of the manipulated object.


\section{Problem Definition and Research Aim}

Humanoid manipulation is a challenging task because of two main reasons: inaccurate forward kinematics and changing environment.
Inaccurate forward kinematics is mostly caused by improper calibrated joint encoders and linkage elasticity. Both issues can only be resolved to some extent by e.g. modelling joint position offsets \cite{Fallon2015} and stiffness coefficients \cite{Johnson2015}. The effect of inaccurate forward kinematics is visualised in \cref{fig:calibration_issue}.
By interacting with objects such as a valve, the robot needs to compensate the applied force by whole body control which likely changes the pose of the manipulated object in the camera frame.

\begin{figure}
\captionsetup{width=0.6\textwidth}
\centering
\includegraphics[width=0.5\textwidth]{images/valkyrie/joint_calibration_issue.png}
\caption{Joint calibration issue resulting in offset of reported pose (solid gray mesh, green marker) from perceived hand pose (coloured point cloud, red marker).}
\label{fig:calibration_issue}
\end{figure}

Both issues are in contrast with open loop industrial robot applications such as moving parts in a assembly line, where stiff actuators manipulate objects at defined poses. Using visual feedback to estimate the configuration of the manipulator and the pose of the manipulated object could be the key step to enable closed-loop manipulation.
In return, visual tracking of highly articulated manipulators and objects causes interesting research questions itself again.

\paragraph{Manipulator tracking}
The main problem of tracking highly articulated manipulators with several degree of freedom is the large variety of their appearance. Using classical object detection methods on this problem would require an enormous training set of different configurations at different lighting conditions. In addition, classification results must be provided at real-time. On one side, the problem can be simplified in the context where a robot is observing its own manipulator by using a robot model representation and its joint encoder values. On the other side, the before mentioned issue of inaccurate forward kinematics reduces the value of these encoder values.

The \emph{primary aim} of this thesis is investigating the effect of using visual perception and reported joint encoder values in conjunction to enable tracking if either of the two information is not available or inaccurate.

\paragraph{Object tracking}
In contrast to the manipulator, we usually have no prior information about the pose of the object up to the point where the manipulator gets in contact with the object. The Amazon Picking Challenge 2015 \cite{Correll2016} showed that detection and tracking of ordinary consumer objects is still a challenging task. Amongst the 25 products used in the challenge were objects of varying appearance (e.g. non rigid objects), objects with meshed material (such as bins) and objects with reflective and translucent material. Classical machine learning approaches that rely on descriptive keypoint features such as SIFT fail in cases where textual information is not available either because of lighting conditions or material properties.

The \emph{secondary aim} of this thesis is the investigation of object tracking with lack of texture.
